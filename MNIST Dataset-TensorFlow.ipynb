{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v1.keras.callbacks' from 'C:\\\\Users\\\\mubashar.nazar\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v1\\\\keras\\\\callbacks\\\\__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "tf.keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data reading\n",
    "data = pd.read_csv(\"./train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting examples and labels\n",
    "X = data.iloc[:,1:]\n",
    "Y = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mubashar.nazar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "#convert dataframe into a ndarray\n",
    "X = X.as_matrix().reshape([X.shape[0], 28,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping 2d examples in 3D\n",
    "X = X.reshape(X.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot encoding\n",
    "Y = pd.get_dummies(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_H0, n_W0, n_C0], name=\"x\")\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, n_y], name=\"y\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "\n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [4,4,1,8], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [2,2,8,16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, outputs):\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    print (X.shape)\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    print (Z1.shape)\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize=[1,8,8,1], strides=[1,8,8,1], padding=\"SAME\")\n",
    "    print (P1.shape)\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    print (Z2.shape)\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize=[1,4,4,1], strides=[1,4,4,1], padding=\"SAME\")\n",
    "    print (P2.shape)\n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    print (P2.shape)\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 10 neurons in output layer.\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, outputs, activation_fn=None)\n",
    "    print (Z3.shape)\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.01,\n",
    "          num_epochs = 1000, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters, len(Y_train.columns))\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name=\"optimizer\").minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            seed = seed + 1\n",
    "              \n",
    "            _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:X_train, Y:Y_train})\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, temp_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(temp_cost)\n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        tf.add_to_collection(\"predict_op\", predict_op)\n",
    "        \n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "#         print(accuracy)\n",
    "        \n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "        saver.save(sess, save_path=\"graph\")\n",
    "    \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n",
      "(?, 28, 28, 8)\n",
      "(?, 4, 4, 8)\n",
      "(?, 4, 4, 16)\n",
      "(?, 1, 1, 16)\n",
      "(?, 16)\n",
      "(?, 10)\n",
      "Cost after epoch 0: 226.943893\n",
      "Cost after epoch 5: 41.436584\n",
      "Cost after epoch 10: 13.325080\n",
      "Cost after epoch 15: 6.645814\n",
      "Cost after epoch 20: 4.278826\n",
      "Cost after epoch 25: 3.050441\n",
      "Cost after epoch 30: 2.679555\n",
      "Cost after epoch 35: 2.461791\n",
      "Cost after epoch 40: 2.366124\n",
      "Cost after epoch 45: 2.303601\n",
      "Cost after epoch 50: 2.257425\n",
      "Cost after epoch 55: 2.222624\n",
      "Cost after epoch 60: 2.188486\n",
      "Cost after epoch 65: 2.154454\n",
      "Cost after epoch 70: 2.119947\n",
      "Cost after epoch 75: 2.087211\n",
      "Cost after epoch 80: 2.053699\n",
      "Cost after epoch 85: 2.022174\n",
      "Cost after epoch 90: 1.992800\n",
      "Cost after epoch 95: 1.966807\n",
      "Cost after epoch 100: 1.941885\n",
      "Cost after epoch 105: 1.916685\n",
      "Cost after epoch 110: 1.891867\n",
      "Cost after epoch 115: 1.868026\n",
      "Cost after epoch 120: 1.845291\n",
      "Cost after epoch 125: 1.823341\n",
      "Cost after epoch 130: 1.801984\n",
      "Cost after epoch 135: 1.780913\n",
      "Cost after epoch 140: 1.759647\n",
      "Cost after epoch 145: 1.738025\n",
      "Cost after epoch 150: 1.716941\n",
      "Cost after epoch 155: 1.696778\n",
      "Cost after epoch 160: 1.677300\n",
      "Cost after epoch 165: 1.658273\n",
      "Cost after epoch 170: 1.639827\n",
      "Cost after epoch 175: 1.622070\n",
      "Cost after epoch 180: 1.604148\n",
      "Cost after epoch 185: 1.586229\n",
      "Cost after epoch 190: 1.568365\n",
      "Cost after epoch 195: 1.550831\n",
      "Cost after epoch 200: 1.533695\n",
      "Cost after epoch 205: 1.517177\n",
      "Cost after epoch 210: 1.501259\n",
      "Cost after epoch 215: 1.486801\n",
      "Cost after epoch 220: 1.473142\n",
      "Cost after epoch 225: 1.460175\n",
      "Cost after epoch 230: 1.447955\n",
      "Cost after epoch 235: 1.436404\n",
      "Cost after epoch 240: 1.425393\n",
      "Cost after epoch 245: 1.414704\n",
      "Cost after epoch 250: 1.404219\n",
      "Cost after epoch 255: 1.393879\n",
      "Cost after epoch 260: 1.383766\n",
      "Cost after epoch 265: 1.373840\n",
      "Cost after epoch 270: 1.364041\n",
      "Cost after epoch 275: 1.354206\n",
      "Cost after epoch 280: 1.344411\n",
      "Cost after epoch 285: 1.334941\n",
      "Cost after epoch 290: 1.325854\n",
      "Cost after epoch 295: 1.316966\n",
      "Cost after epoch 300: 1.308212\n",
      "Cost after epoch 305: 1.299647\n",
      "Cost after epoch 310: 1.291141\n",
      "Cost after epoch 315: 1.282614\n",
      "Cost after epoch 320: 1.274222\n",
      "Cost after epoch 325: 1.265959\n",
      "Cost after epoch 330: 1.257967\n",
      "Cost after epoch 335: 1.250177\n",
      "Cost after epoch 340: 1.242459\n",
      "Cost after epoch 345: 1.234883\n",
      "Cost after epoch 350: 1.227258\n",
      "Cost after epoch 355: 1.218666\n",
      "Cost after epoch 360: 1.210266\n",
      "Cost after epoch 365: 1.200826\n",
      "Cost after epoch 370: 1.191976\n",
      "Cost after epoch 375: 1.183373\n",
      "Cost after epoch 380: 1.174836\n",
      "Cost after epoch 385: 1.166123\n",
      "Cost after epoch 390: 1.157585\n",
      "Cost after epoch 395: 1.149191\n",
      "Cost after epoch 400: 1.140893\n",
      "Cost after epoch 405: 1.132589\n",
      "Cost after epoch 410: 1.124228\n",
      "Cost after epoch 415: 1.115872\n",
      "Cost after epoch 420: 1.107572\n",
      "Cost after epoch 425: 1.099327\n",
      "Cost after epoch 430: 1.091080\n",
      "Cost after epoch 435: 1.082746\n",
      "Cost after epoch 440: 1.074526\n",
      "Cost after epoch 445: 1.066527\n",
      "Cost after epoch 450: 1.058622\n",
      "Cost after epoch 455: 1.050759\n",
      "Cost after epoch 460: 1.043093\n",
      "Cost after epoch 465: 1.035604\n",
      "Cost after epoch 470: 1.028262\n",
      "Cost after epoch 475: 1.021058\n",
      "Cost after epoch 480: 1.013997\n",
      "Cost after epoch 485: 1.006961\n",
      "Cost after epoch 490: 0.999255\n",
      "Cost after epoch 495: 0.991091\n",
      "Cost after epoch 500: 0.983920\n",
      "Cost after epoch 505: 0.977127\n",
      "Cost after epoch 510: 0.970200\n",
      "Cost after epoch 515: 0.963590\n",
      "Cost after epoch 520: 0.957142\n",
      "Cost after epoch 525: 0.950809\n",
      "Cost after epoch 530: 0.944472\n",
      "Cost after epoch 535: 0.938086\n",
      "Cost after epoch 540: 0.931579\n",
      "Cost after epoch 545: 0.924810\n",
      "Cost after epoch 550: 0.917536\n",
      "Cost after epoch 555: 0.909403\n",
      "Cost after epoch 560: 0.900075\n",
      "Cost after epoch 565: 0.889574\n",
      "Cost after epoch 570: 0.878681\n",
      "Cost after epoch 575: 0.867986\n",
      "Cost after epoch 580: 0.857607\n",
      "Cost after epoch 585: 0.847728\n",
      "Cost after epoch 590: 0.838278\n",
      "Cost after epoch 595: 0.829070\n",
      "Cost after epoch 600: 0.820223\n",
      "Cost after epoch 605: 0.811640\n",
      "Cost after epoch 610: 0.803526\n",
      "Cost after epoch 615: 0.795919\n",
      "Cost after epoch 620: 0.788528\n",
      "Cost after epoch 625: 0.781461\n",
      "Cost after epoch 630: 0.774857\n",
      "Cost after epoch 635: 0.767771\n",
      "Cost after epoch 640: 0.761087\n",
      "Cost after epoch 645: 0.754592\n",
      "Cost after epoch 650: 0.748079\n",
      "Cost after epoch 655: 0.741824\n",
      "Cost after epoch 660: 0.736515\n",
      "Cost after epoch 665: 0.730736\n",
      "Cost after epoch 670: 0.725672\n",
      "Cost after epoch 675: 0.721833\n",
      "Cost after epoch 680: 0.716377\n",
      "Cost after epoch 685: 0.711116\n",
      "Cost after epoch 690: 0.705913\n",
      "Cost after epoch 695: 0.700909\n",
      "Cost after epoch 700: 0.696241\n",
      "Cost after epoch 705: 0.691807\n",
      "Cost after epoch 710: 0.687497\n",
      "Cost after epoch 715: 0.683325\n",
      "Cost after epoch 720: 0.679056\n",
      "Cost after epoch 725: 0.674993\n",
      "Cost after epoch 730: 0.671147\n",
      "Cost after epoch 735: 0.668470\n",
      "Cost after epoch 740: 0.663626\n",
      "Cost after epoch 745: 0.659966\n",
      "Cost after epoch 750: 0.656080\n",
      "Cost after epoch 755: 0.652665\n",
      "Cost after epoch 760: 0.649240\n",
      "Cost after epoch 765: 0.645604\n",
      "Cost after epoch 770: 0.642166\n",
      "Cost after epoch 775: 0.638994\n",
      "Cost after epoch 780: 0.636112\n",
      "Cost after epoch 785: 0.633139\n",
      "Cost after epoch 790: 0.630446\n",
      "Cost after epoch 795: 0.627808\n",
      "Cost after epoch 800: 0.626348\n",
      "Cost after epoch 805: 0.623318\n",
      "Cost after epoch 810: 0.621382\n",
      "Cost after epoch 815: 0.618305\n",
      "Cost after epoch 820: 0.615734\n",
      "Cost after epoch 825: 0.613782\n",
      "Cost after epoch 830: 0.611673\n",
      "Cost after epoch 835: 0.609324\n",
      "Cost after epoch 840: 0.607043\n",
      "Cost after epoch 845: 0.604905\n",
      "Cost after epoch 850: 0.602927\n",
      "Cost after epoch 855: 0.600746\n",
      "Cost after epoch 860: 0.598721\n",
      "Cost after epoch 865: 0.596531\n",
      "Cost after epoch 870: 0.594494\n",
      "Cost after epoch 875: 0.592203\n",
      "Cost after epoch 880: 0.589993\n",
      "Cost after epoch 885: 0.588943\n",
      "Cost after epoch 890: 0.584974\n",
      "Cost after epoch 895: 0.581941\n",
      "Cost after epoch 900: 0.579291\n",
      "Cost after epoch 905: 0.576407\n",
      "Cost after epoch 910: 0.573632\n",
      "Cost after epoch 915: 0.571109\n",
      "Cost after epoch 920: 0.568596\n",
      "Cost after epoch 925: 0.566232\n",
      "Cost after epoch 930: 0.563824\n",
      "Cost after epoch 935: 0.561332\n",
      "Cost after epoch 940: 0.558832\n",
      "Cost after epoch 945: 0.556344\n",
      "Cost after epoch 950: 0.553878\n",
      "Cost after epoch 955: 0.551397\n",
      "Cost after epoch 960: 0.548924\n",
      "Cost after epoch 965: 0.546464\n",
      "Cost after epoch 970: 0.543844\n",
      "Cost after epoch 975: 0.541163\n",
      "Cost after epoch 980: 0.538230\n",
      "Cost after epoch 985: 0.535119\n",
      "Cost after epoch 990: 0.531743\n",
      "Cost after epoch 995: 0.528425\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHmtJREFUeJzt3XuUHWWd7vHvs3cnHUgIEEgwQELACSJeQCcCHnUGBy/AqOgMOHBUojIn6oEz6niWB9QlzHA4i1HxNl4GlJsziqJ4iciAmFFRGZDgAHKLiVwkJiThFhJuSXf/zh/17k71Tu3anZDde3fX81lrr9r11ltVb3Ul/XTd3lJEYGZm1qzW7QaYmVlvckCYmVkhB4SZmRVyQJiZWSEHhJmZFXJAmJlZIQeEVY6kf5e0sNvtMOt1DggbM5Luk/SabrcjIo6JiEu73Q4AST+T9LdjsJ5+SRdJelzSg5L+vk39D6Z669N8/blpZ0v6raQBSWd1uu3WPQ4Im1Ak9XW7DQ291BbgLGA+sB/wauDDko4uqijp9cDpwFHAPOAA4B9yVVYAHwZ+1LnmWi9wQFhPkPQGSbdIekzS9ZJenJt2uqTfS9og6U5Jb8lNe6ekX0n6jKRHgLNS2S8lfUrSo5LulXRMbp7hv9pHUXd/Sdeldf9E0hcl/VuLbThS0kpJ/0fSg8DFknaXdKWkdWn5V0raN9U/B3gV8AVJGyV9IZUfJOlaSY9IWibprTvgR3wycHZEPBoRdwFfAd7Zou5C4MKIuCMiHgXOzteNiEsj4t+BDTugXdbDHBDWdZJeClwEvAfYAzgfWJw7rfF7sl+ku5L9JftvkmbnFnE4cA8wCzgnV7YM2BP4BHChJLVoQlndbwC/Tu06C3hHm815DjCD7C/1RWT/xy5O43OBp4AvAETER4FfAKdFxLSIOE3SVODatN5ZwEnAlyS9oGhlkr6UQrXoc1uqszuwN3BrbtZbgcJlpvLmuntJ2qPNttsE44CwXvA/gPMj4saIGEzXB54BjgCIiG9HxKqIGIqIbwHLgcNy86+KiH+OiIGIeCqV3R8RX4mIQeBSYDawV4v1F9aVNBd4GfDxiNgUEb8EFrfZliHgzIh4JiKeioiHI+KKiHgyIjaQBdifl8z/BuC+iLg4bc9vgCuA44sqR8T/jIjdWnwaR2HT0nB9btb1wC4t2jCtoC4l9W2CckBYL9gP+FD+r19gDtlfvUg6OXf66THghWR/7Tc8ULDMBxtfIuLJ9HVaQb2yunsDj+TKWq0rb11EPN0YkbSzpPMl3S/pceA6YDdJ9Rbz7wcc3vSzeBvZkcn22piG03Nl02l9imhjQV1K6tsE5YCwXvAAcE7TX787R8RlkvYjO19+GrBHROwG3A7kTxd1qkvi1cAMSTvnyua0mae5LR8CngccHhHTgT9L5WpR/wHg500/i2kR8b6ilUn6l3T9ouhzB0C6jrAaOCQ36yHAHS224Y6Cumsi4uHWm20TkQPCxtokSVNynz6yAHivpMOVmSrpLyXtAkwl+yW6DkDSu8iOIDouIu4HlpJd+J4s6eXAG7dxMbuQXXd4TNIM4Mym6WvI7hJquBI4UNI7JE1Kn5dJen6LNr43BUjRJ3+N4WvAx9JF84PITutd0qLNXwNOkXRwun7xsXzd1KYpZL8/+tJ+bHVEZOOYA8LG2lVkvzAbn7MiYinZL6wvAI+S3Ub5ToCIuBM4D/hPsl+mLwJ+NYbtfRvwcuBh4P8C3yK7PjJanwV2Ah4CbgCubpr+OeD4dIfT59N1itcBJwKryE5//RPQz7NzJtnF/vuBnwOfjIirASTNTUcccwFS+SeAn6b69zMy2L5Ctu9OAj6avre7eG/jkPzCILPRk/Qt4O6IaD4SMJtwfARhViKd3nmupJqyB8uOA77f7XaZjYVeetLTrBc9B/gu2XMQK4H3RcR/dbdJZmPDp5jMzKyQTzGZmVmhcX2Kac8994x58+Z1uxlmZuPKzTff/FBEzGxXb1wHxLx581i6dGm3m2FmNq5Iun809XyKyczMCjkgzMyskAPCzMwKOSDMzKyQA8LMzAo5IMzMrJADwszMClUyIJY9uIHzfryMhzZuS6/NZmbVUsmAWL52A//8Hyt45IlN3W6KmVnPqmRA1JS97XHIHRWambVUyYAYfhmw88HMrKVqBkRKCAeEmVlrFQ2ILCECJ4SZWSvVDIg09BGEmVlr1QyIxhGEA8LMrKVKBkStcQ3Cp5jMzFqqZEA0LlIPOR/MzFqqZkDQOMXkhDAza6WaATF8isnMzFqpaED4CMLMrJ1qBkQaOh/MzFqrZEDUhh+UMzOzVioZEMN3Mfk2JjOzlqoZEGnoeDAza62aAeEnqc3M2qpoQGRD38VkZtZaNQMiDR0PZmatVTIgajWfYjIza6eSAdE4gvArR83MWutYQEiaI+mnku6SdIek96fyGZKulbQ8DXdP5ZL0eUkrJN0m6aWda1s2dDyYmbXWySOIAeBDEfF84AjgVEkHA6cDSyJiPrAkjQMcA8xPn0XAlzvVMHe1YWbWXscCIiJWR8Rv0vcNwF3APsBxwKWp2qXAm9P344CvReYGYDdJszvRNne1YWbW3phcg5A0D3gJcCOwV0SshixEgFmp2j7AA7nZVqay5mUtkrRU0tJ169Ztb3sAvzDIzKxMxwNC0jTgCuADEfF4WdWCsq1+g0fEBRGxICIWzJw5c7vaNPxGOeeDmVlLHQ0ISZPIwuHrEfHdVLymceooDdem8pXAnNzs+wKrOtKulEXuisnMrLVO3sUk4ELgroj4dG7SYmBh+r4Q+EGu/OR0N9MRwPrGqagd37Zs6IvUZmat9XVw2a8A3gH8VtItqewjwLnA5ZJOAf4AnJCmXQUcC6wAngTe1amG+TZXM7P2OhYQEfFLiq8rABxVUD+AUzvVnjy/k9rMrL1qPknti9RmZm1VMiD8Rjkzs/YqGRDDb5TzIYSZWUvVDIg0dD6YmbVWzYDwKSYzs7YqGhDZ0HcxmZm1Vs2ASEPng5lZa5UMiJo76zMza6uSATF8F9NQd9thZtbLqhkQ+CK1mVk71QwIX6Q2M2ur4gHR3XaYmfWyigaEL1KbmbVTyYDwG+XMzNqrZED4jXJmZu1VMyCGXxjkhDAza6XaAeF8MDNrqZoB4TfKmZm1Vc2A8DupzczaqmRADPfF5IQwM2upkgHR6M3Vb5QzM2utmgHhi9RmZm1VNCDcWZ+ZWTsVDYhs6LuYzMxaq2ZApKHzwcystUoGhN8oZ2bWXiUDYviNcs4HM7OWqhkQ+DkIM7N2qhkQ7qzPzKytageE88HMrKVqBoQ76zMza6uSAeE3ypmZtVfJgGg8Se27mMzMWqtmQKShL1KbmbXWsYCQdJGktZJuz5WdJemPkm5Jn2Nz086QtELSMkmv71S7snVlQ59iMjNrrZNHEJcARxeUfyYiDk2fqwAkHQycCLwgzfMlSfVONWy4sz4nhJlZSx0LiIi4DnhklNWPA74ZEc9ExL3ACuCwTrUNsqMIx4OZWWvduAZxmqTb0imo3VPZPsADuTorU9lWJC2StFTS0nXr1m13I2qSTzGZmZUY64D4MvBc4FBgNXBeKldB3cJf3xFxQUQsiIgFM2fO3O6GCL9RzsyszJgGRESsiYjBiBgCvsKW00grgTm5qvsCqzrZFp9iMjMrN6YBIWl2bvQtQOMOp8XAiZL6Je0PzAd+3eG2+BSTmVmJvk4tWNJlwJHAnpJWAmcCR0o6lOyP9/uA9wBExB2SLgfuBAaAUyNisFNtg+wUk+9iMjNrrWMBEREnFRRfWFL/HOCcTrWnmU8xmZmVq+ST1NC4i8kRYWbWSmUDIruLqdutMDPrXdUNCF+kNjMrVeGAcGd9ZmZlqhsQuLM+M7My1Q0IX6Q2MytV4YDwba5mZmUqGxA1yX0xmZmVqGxA+BqEmVm56gaETzGZmZWqcED4OQgzszLVDQjcWZ+ZWZnqBoR8DcLMrExlA6Im+UlqM7MSlQ0Id9ZnZlauugHhi9RmZqUqHBDurM/MrEy1A8L5YGbW0qgCQtIJoykbT4Q76zMzKzPaI4gzRlk2btT8JLWZWam+somSjgGOBfaR9PncpOnAQCcb1mmSfBeTmVmJ0oAAVgFLgTcBN+fKNwAf7FSjxoKfpDYzK1caEBFxK3CrpG9ExGYASbsDcyLi0bFoYKe4sz4zs3KjvQZxraTpkmYAtwIXS/p0B9vVcX6jnJlZudEGxK4R8TjwV8DFEfGnwGs616zO8/sgzMzKjTYg+iTNBt4KXNnB9oyZmp+kNjMrNdqA+EfgGuD3EXGTpAOA5Z1rVudJ+JWjZmYl2t3FBEBEfBv4dm78HuCvO9WoseJ4MDNrbbRPUu8r6XuS1kpaI+kKSft2unGd5FNMZmblRnuK6WJgMbA3sA/ww1Q2bmV9MTkhzMxaGW1AzIyIiyNiIH0uAWZ2sF0d5+cgzMzKjTYgHpL0dkn19Hk78HAnG9ZpNT8HYWZWarQB8W6yW1wfBFYDxwPv6lSjxoLfKGdmVm5UdzEBZwMLG91rpCeqP0UWHOOT5FNMZmYlRnsE8eJ830sR8Qjwks40aWzUfJHazKzUaAOiljrpA4aPINp1FX5Rui329vx8kq6VtDwNd0/lkvR5SSsk3SbppduzMdvCXW2YmZUbbUCcB1wv6WxJ/whcD3yizTyXAEc3lZ0OLImI+cCSNA5wDDA/fRYBXx5lu7abJL+T2sysxKgCIiK+Rvbk9BpgHfBXEfGvbea5Dnikqfg44NL0/VLgzbnyr0XmBmC31PdTx9T8Tmozs1KjvUhNRNwJ3Pks17dXRKxOy1staVYq3wd4IFdvZSpb3bwASYvIjjKYO3fudjdEyH0xmZmVGO0ppk5TQVnhb++IuCAiFkTEgpkzn8Wzej6CMDMrNdYBsaZx6igN16bylcCcXL19yV532jE1P0ltZlZqrANiMbAwfV8I/CBXfnK6m+kIYH3jVFSnCD9JbWZWZtTXILaVpMuAI4E9Ja0EzgTOBS6XdArwB+CEVP0q4FhgBfAkY/CUtnyKycysVMcCIiJOajHpqIK6AZzaqbYUqflJajOzUr1ykXrM+Y1yZmblKhsQ9ZoYcm99ZmYtVTYg+mpiwAFhZtZSZQOiXhMDgw4IM7NWKhsQfbUaA0ND3W6GmVnPqm5A1MWgTzGZmbVU2YCo+xqEmVmpygZEX81HEGZmZSobEPVazUcQZmYlKhsQPoIwMytX2YCo18TmQd/FZGbWSmUDwkcQZmblqhsQdV+DMDMrU92A8BGEmVmpygZEPQWEXxpkZlassgHRV8teg+2jCDOzYpUNiHo9CwhfhzAzK1bZgGgcQTggzMyKVTYg6rVs0wfd5beZWaHKBsSk4VNMfljOzKxIZQOi7ovUZmalKhsQvgZhZlausgExfA3CAWFmVqiyAeEjCDOzcpUNiMY1iAH36GpmVqiyAeEjCDOzctUNiLqvQZiZlaluQPgIwsysVGUDYstzEL4GYWZWpLIBMXwE4a42zMwKVTYg/CS1mVm5ygZEX+qLabMDwsysUGUDYsuT1L4GYWZWpLIB4WsQZmblqhsQdV+DMDMr09eNlUq6D9gADAIDEbFA0gzgW8A84D7grRHxaKfa4OcgzMzKdfMI4tURcWhELEjjpwNLImI+sCSNd4x7czUzK9dLp5iOAy5N3y8F3tzJlTWOIDa7sz4zs0LdCogAfizpZkmLUtleEbEaIA1nFc0oaZGkpZKWrlu3brsbMCn1xbTJAWFmVqgr1yCAV0TEKkmzgGsl3T3aGSPiAuACgAULFmz3+aGd++sAPLVpcHsXYWY2oXXlCCIiVqXhWuB7wGHAGkmzAdJwbSfbMHVylo0bnxno5GrMzMatMQ8ISVMl7dL4DrwOuB1YDCxM1RYCP+hkO+o1MWVSjSd9BGFmVqgbp5j2Ar4nqbH+b0TE1ZJuAi6XdArwB+CETjdkWn+fjyDMzFoY84CIiHuAQwrKHwaOGsu27Dy5jycdEGZmhXrpNtcxt/PkOk/4FJOZWaFKB8S0/j6e8BGEmVmhSgfEzv19PoIwM2uh0gExrb/uIwgzsxYqHRC+SG1m1lqlA2Lq5LpvczUza6HaAdHfx5ObBolwj65mZs0qHxADQ+EO+8zMClQ7ICZnHfY98YzvZDIza1bpgNi5P3uQ3HcymZltrdIB0ejR9YlNDggzs2bVDoh+n2IyM2ul4gHhU0xmZq1UOiCm9fulQWZmrVQ6IKbvNAmADU9v7nJLzMx6T7UDYkp2BPH4Uz6CMDNrVumAmDq5j5rgcR9BmJltpdIBUauJXaZM4vGnHBBmZs0qHRAA03fqY8PTPsVkZtbMATFlkk8xmZkVcEBMmeSL1GZmBRwQO/X5CMLMrIADYsok1vsitZnZViofEDOmTebhjZv80iAzsyaVD4jZ06ewaXCIR57Y1O2mmJn1lMoHxHN23QmAVY893eWWmJn1lsoHxIF7TQPgrtWPd7klZma9pfIBMW+PqUzr7+O2Pz7W7aaYmfWUygdErSZeuM90bn1gfbebYmbWUyofEABHHLAHt69az8Mbn+l2U8zMeoYDAviLg2YRAUvuXtvtppiZ9QwHBPDCvXdl/qxpXPTLexkYHOp2c8zMeoIDguw6xN+/9kDufnADn7xmWbebY2bWExwQyTEvms3bj5jL+dfdw2d/8js2+0jCzCqur9sNaCbpaOBzQB34akScO1brPuuNL+CJZwb57E+Wc+Ev7uX5s6dzwMyp7Dmtn6n9fUzrrzO5r0ZfrcakvhqTamJSPfe9r0a9JvpqoibRV899r9WojxgX9bqoS8Pz1GtC0lhtrplZqZ4KCEl14IvAa4GVwE2SFkfEnWOx/r56jU+/9RCOO3Rvrr1zDcvXbOTaO9fw6JObGBqjrppqgr5ajVotG9ZTcOSDpz4cJlCTqKWhct9rtdx3MXLaNk4vWk+9tqVu1u6sniAbDo83lZMtB2mrssZ8pPJaU53h5Q6XbWl3y+WRVVS+jbnljWy7Rix3xHegVhu5vMa68/Mxot1tlqctbcivv/lnCVv20dY/j5HljXXTvLzcfFkbi5eXN9w2lGtjY1oqa67rP3AmlJ4KCOAwYEVE3AMg6ZvAccCYBERaJ0c+bxZHPm/WcFlE8PTmITY+M8DmwaHcJ5qGQwwOBYNDwUAa5seHhsuHRtaJYHAw1YmieYcYHILBoaHh5QwFDEUQaZh9srYOlkxvrLtRd2h4emM8mz9y5c3LGRzaUrcxnUY9IBvN5hnxPf0sG3Vs4tsSMo3xFsHCyIoqmNZuWbSaPqo2tKqb25amOkXLzBtRr3k7C9ZVuE0F29Wod+LL5vC3rzpgq/XuSL0WEPsAD+TGVwKH5ytIWgQsApg7d+6YNEoSO02us9Pk+pisryoiRgbHUC5Msun50MmFT2wdOI2QygfUUK5u2fIYrjsy2IbSjPnyoab5srKm9rUIxy1tHLmO5uU16ua3kXxZftu3CuAtyyS37NLlDa8/Wxa58eZ9ldVhRJ3meYKRFUZbf8T0raaNYp4W7W5Xv3kaBctqnq9we1vUa96Wona1Xt7W9Roje07rp9N6LSCKjk9H/mwiLgAuAFiwYIH/Dh3HGqdd0lg3m2JmBXrtLqaVwJzc+L7Aqi61xcys0notIG4C5kvaX9Jk4ERgcZfbZGZWST11iikiBiSdBlxDdpvrRRFxR5ebZWZWST0VEAARcRVwVbfbYWZWdb12isnMzHqEA8LMzAo5IMzMrJADwszMCimaHz0cRyStA+7fztn3BB7agc0ZD7zN1eBtroZns837RcTMdpXGdUA8G5KWRsSCbrdjLHmbq8HbXA1jsc0+xWRmZoUcEGZmVqjKAXFBtxvQBd7mavA2V0PHt7my1yDMzKxclY8gzMyshAPCzMwKVTIgJB0taZmkFZJO73Z7dhRJcyT9VNJdku6Q9P5UPkPStZKWp+HuqVySPp9+DrdJeml3t2D7SKpL+i9JV6bx/SXdmLb3W6nreCT1p/EVafq8brb72ZC0m6TvSLo77e+XT+T9LOmD6d/07ZIukzRlIu5nSRdJWivp9lzZNu9XSQtT/eWSFm5veyoXEJLqwBeBY4CDgZMkHdzdVu0wA8CHIuL5wBHAqWnbTgeWRMR8YEkah+xnMD99FgFfHvsm7xDvB+7Kjf8T8Jm0vY8Cp6TyU4BHI+JPgM+keuPV54CrI+Ig4BCy7Z+Q+1nSPsDfAQsi4oVkrwI4kYm5ny8Bjm4q26b9KmkGcCbZ65oPA85shMo2y941W50P8HLgmtz4GcAZ3W5Xh7b1B8BrgWXA7FQ2G1iWvp8PnJSrP1xvvHzI3jq4BPgL4Eqyd5c+BPQ172+y94y8PH3vS/XU7W3Yjm2eDtzb3PaJup/Z8q76GWm/XQm8fqLuZ2AecPv27lfgJOD8XPmIetvyqdwRBFv+sTWsTGUTSjqsfglwI7BXRKwGSMNZqdpE+Fl8FvgwMJTG9wAei4iBNJ7fpuHtTdPXp/rjzQHAOuDidGrtq5KmMkH3c0T8EfgU8AdgNdl+u5mJv58btnW/7rD9XcWAUEHZhLrXV9I04ArgAxHxeFnVgrJx87OQ9AZgbUTcnC8uqBqjmDae9AEvBb4cES8BnmDLaYci43q70+mR44D9gb2BqWSnV5pNtP3cTqvt3GHbX8WAWAnMyY3vC6zqUlt2OEmTyMLh6xHx3VS8RtLsNH02sDaVj/efxSuAN0m6D/gm2WmmzwK7SWq8LTG/TcPbm6bvCjwylg3eQVYCKyPixjT+HbLAmKj7+TXAvRGxLiI2A98F/hsTfz83bOt+3WH7u4oBcRMwP90BMZnsYtfiLrdph5Ak4ELgroj4dG7SYqBxJ8NCsmsTjfKT090QRwDrG4ey40FEnBER+0bEPLL9+B8R8Tbgp8DxqVrz9jZ+Dsen+uPuL8uIeBB4QNLzUtFRwJ1M0P1MdmrpCEk7p3/jje2d0Ps5Z1v36zXA6yTtno6+XpfKtl23L8h06SLQscDvgN8DH+12e3bgdr2S7FDyNuCW9DmW7PzrEmB5Gs5I9UV2R9fvgd+S3SXS9e3Yzm0/ErgyfT8A+DWwAvg20J/Kp6TxFWn6Ad1u97PY3kOBpWlffx/YfSLvZ+AfgLuB24F/Bfon4n4GLiO7zrKZ7EjglO3Zr8C70/avAN61ve1xVxtmZlaoiqeYzMxsFBwQZmZWyAFhZmaFHBBmZlbIAWFmZoUcENaTJF2fhvMk/fcdvOyPFK2rUyS9WdLHO7Tsj7Svtc3LfJGkS3b0cm388W2u1tMkHQn874h4wzbMU4+IwZLpGyNi2o5o3yjbcz3wpoh46FkuZ6vt6tS2SPoJ8O6I+MOOXraNHz6CsJ4kaWP6ei7wKkm3pHcC1CV9UtJNqQ/896T6Ryp7F8Y3yB4aQtL3Jd2c3iOwKJWdC+yUlvf1/LrSE6mfTO8c+K2kv8kt+2fa8v6Fr6cnepF0rqQ7U1s+VbAdBwLPNMJB0iWS/kXSLyT9LvUn1Xinxai2K7fsom15u6Rfp7LzU/f2SNoo6RxJt0q6QdJeqfyEtL23Srout/gfkj2dblXW7ScH/fGn6ANsTMMjSU9Ip/FFwMfS936yp4n3T/WeAPbP1W08cboT2RO4e+SXXbCuvwauJXvfwF5kXTzMTsteT9anTQ34T7Kn1meQdbHcOBLfrWA73gWclxu/BLg6LWc+2dOyU7Zlu4ranr4/n+wX+6Q0/iXg5PQ9gDem75/Ireu3wD7N7Sfr5+qH3f534E93P42OrszGi9cBL5bU6INnV7JftJuAX0fEvbm6fyfpLen7nFTv4ZJlvxK4LLLTOGsk/Rx4GfB4WvZKAEm3kPXZfwPwNPBVST8ie09Bs9lkXXPnXR4RQ8BySfcAB23jdrVyFPCnwE3pAGcntnTstinXvpvJ3hMC8CvgEkmXk3WC17CWrOdUqzAHhI03Av5XRIzofCxdq3iiafw1ZC+OeVLSz8j+Um+37FaeyX0fJHtRzYCkw8h+MZ8InEbWo2zeU2S/7POaL/w1umhuu11tCLg0Is4omLY5IhrrHST934+I90o6HPhL4BZJh0bEw2Q/q6dGuV6boHwNwnrdBmCX3Pg1wPuUdWuOpAOVvSyn2a5kr518UtJBZK9gbdjcmL/JdcDfpOsBM4E/I+vsrZCy927sGhFXAR8g60Cv2V3AnzSVnSCpJum5ZB3OLduG7WqW35YlwPGSZqVlzJC0X9nMkp4bETdGxMfJ3rzW6Cb6QLLTclZhPoKwXncbMCDpVrLz958jO73zm3SheB3w5oL5rgbeK+k2sl/AN+SmXQDcJuk3kXUP3vA9sldX3kr2V/2HI+LBFDBFdgF+IGkK2V/vHyyocx1wniTl/oJfBvyc7DrHeyPiaUlfHeV2NRuxLZI+BvxYUo2sR9BTgftL5v+kpPmp/UvStgO8GvjRKNZvE5hvczXrMEmfI7vg+5P0fMGVEfGdLjerJUn9ZAH2ytjySk+rIJ9iMuu8/wfs3O1GbIO5wOkOB/MRhJmZFfIRhJmZFXJAmJlZIQeEmZkVckCYmVkhB4SZmRX6/1XCacXzt7niAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8350794\n",
      "Test Accuracy: 0.8290476\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mubashar.nazar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"./test.csv\", sep=\",\")\n",
    "test = test.as_matrix().reshape([test.shape[0], 28,28])\n",
    "test = test.reshape(test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    G = tf.Graph()\n",
    "    result = []\n",
    "    with tf.Session(graph=G) as sess:\n",
    "        new_saver = tf.train.import_meta_graph('graph.meta')\n",
    "        new_saver.restore(sess, 'graph')\n",
    "        predict_op = tf.get_collection(\"predict_op\")[0]\n",
    "\n",
    "        X = G.get_operation_by_name(\"x\").outputs[0]\n",
    "        p = sess.run([predict_op], feed_dict={X: test})\n",
    "        print (p)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from graph\n",
      "[array([2, 0, 9, ..., 3, 4, 2], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "testData = save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./submission.csv')\n",
    "submission['Label'] = testData[0]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
